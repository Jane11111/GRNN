n_layers: 1
n_heads: 1
hidden_size: 128
inner_size: 128
hidden_dropout_prob: 0.2
attn_dropout_prob: 0.2
hidden_act: 'gelu'
layer_norm_eps: 1e-12
initializer_range: 0.02
step: 1
weight: 0.6
reg_weight: 5e-5
loss_type: 'CE'